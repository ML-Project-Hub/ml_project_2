{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "syn_input_data = np.genfromtxt('Info/input.csv', delimiter=',')\n",
    "syn_output_data = np.genfromtxt(\n",
    "'Info/output.csv', delimiter=',').reshape([-1, 1])\n",
    "letor_input_data = np.genfromtxt(\n",
    "'Info/Querylevelnorm_X.csv', delimiter=',')\n",
    "letor_output_data = np.genfromtxt(\n",
    "'Info/Querylevelnorm_t.csv', delimiter=',').reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_design_matrix(X, centers, spreads):\n",
    "    # use broadcast\n",
    "    basis_func_outputs = np.exp(np.sum(np.matmul(X - centers, spreads) * (X - centers),axis=2)/(-2)).T\n",
    "    # insert ones to the 1st col\n",
    "    return np.insert(basis_func_outputs, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def closed_form_sol(L2_lambda, design_matrix, output_data):\n",
    "    return np.linalg.solve(\n",
    "    L2_lambda * np.identity(design_matrix.shape[1]) +\n",
    "    np.matmul(design_matrix.T, design_matrix),\n",
    "    np.matmul(design_matrix.T, output_data)\n",
    "    ).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_sol(learning_rate,minibatch_size,num_epochs,L2_lambda,design_matrix,output_data):\n",
    "    N, _ = design_matrix.shape\n",
    "    # You can try different mini-batch size size\n",
    "    # Using minibatch_size = N is equivalent to standard gradient descent\n",
    "    # Using minibatch_size = 1 is equivalent to stochastic gradient descent\n",
    "    # In this case, minibatch_size = N is better\n",
    "    weights = np.zeros([1, 4])\n",
    "    # The more epochs the higher training accuracy. When set to 1000000,\n",
    "    # weights will be very close to closed_form_weights. But this is unnecessary\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(N / minibatch_size):\n",
    "            lower_bound = i * minibatch_size\n",
    "            upper_bound = min((i+1)*minibatch_size, N)\n",
    "            Phi = design_matrix[lower_bound : upper_bound, :]\n",
    "            t = output_data[lower_bound : upper_bound, :]\n",
    "            E_D = np.matmul((np.matmul(Phi, weights.T)-t).T,Phi)\n",
    "            E = (E_D + L2_lambda * weights) / minibatch_size\n",
    "            weights = weights - learning_rate * E\n",
    "            #print np.linalg.norm(E)\n",
    "    return weights.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = syn_input_data\n",
    "output_data = syn_output_data\n",
    "N, D = input_data.shape\n",
    "# Assume we use 3 Gaussian basis functions M = 3\n",
    "# shape = [M, 1, D]\n",
    "centers = np.array([np.ones((D))*1, np.ones((D))*0.5, np.ones((D))*1.5])\n",
    "centers = centers[:, np.newaxis, :]\n",
    "# shape = [M, D, D]\n",
    "spreads = np.array([np.identity(D), np.identity(D), np.identity(D)]) * 0.5\n",
    "# shape = [1, N, D]\n",
    "X = input_data[np.newaxis, :, :]\n",
    "design_matrix = compute_design_matrix(X, centers, spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.35228143,  0.78618824,  0.04522565],\n",
       "       [ 1.        ,  0.27040822,  0.76142183,  0.02751353],\n",
       "       [ 1.        ,  0.77751696,  0.83165481,  0.20826128],\n",
       "       ..., \n",
       "       [ 1.        ,  0.5760231 ,  0.80675205,  0.11783427],\n",
       "       [ 1.        ,  0.3614176 ,  0.77978949,  0.04799247],\n",
       "       [ 1.        ,  0.35121316,  0.73774718,  0.04790335]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.41005736 -6.06152578  8.20880053  5.50901759]\n",
      "[-3.30025941 -4.1399126   7.5356907  -0.17730426]\n"
     ]
    }
   ],
   "source": [
    "# Closed-form solution\n",
    "print closed_form_sol(L2_lambda=0.1,design_matrix=design_matrix,output_data=output_data)\n",
    "# Gradient descent solution\n",
    "print SGD_sol(learning_rate=1,minibatch_size=N,num_epochs=10000,L2_lambda=0.1,design_matrix=design_matrix,output_data=output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
