{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "syn_input_data = np.genfromtxt('Info/input.csv', delimiter=',')\n",
    "syn_output_data = np.genfromtxt('Info/output.csv', delimiter=',').reshape([-1, 1])\n",
    "letor_input_data = np.genfromtxt('Info/Querylevelnorm_X.csv', delimiter=',')\n",
    "letor_output_data = np.genfromtxt('Info/Querylevelnorm_t.csv', delimiter=',').reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle(input_data):\n",
    "    indices = [i for i in range(len(input_data))]\n",
    "    random.shuffle(indices)\n",
    "    return indices\n",
    "    \n",
    "def split_data(input_data,indices):\n",
    "    length = len(indices)\n",
    "    training_data = [input_data[indices[i]] for i in range(int(length*0.8))]\n",
    "    validation_data = [input_data[indices[i]] for i in range(int(length*0.8),int(length*0.9))]\n",
    "    test_data = [input_data[indices[i]] for i in range(int(length*0.9),length)]\n",
    "    total_data = [input_data[indices[i]] for i in range(length)]\n",
    "    return np.array(training_data),np.array(validation_data),np.array(test_data),np.array(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_means(k,input_data):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=None, precompute_distances=True, n_init=30).fit(input_data)\n",
    "    dic = {}\n",
    "    labels = kmeans.labels_\n",
    "    centers = kmeans.cluster_centers_\n",
    "    for i in range(len(labels)):\n",
    "        try:\n",
    "            dic[labels[i]] += [input_data[i]]\n",
    "        except:\n",
    "            dic[labels[i]] = [input_data[i]]\n",
    "\n",
    "    for i in dic.keys():\n",
    "        listty = np.matrix(dic[i])\n",
    "        dic[i] = {}\n",
    "        dic[i][\"val\"] = listty\n",
    "        dic[i][\"center\"] = list(centers[i])\n",
    "        dic[i][\"spread\"] = np.linalg.pinv(np.matrix(np.cov(listty.T)))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Given in ppt\n",
    "def compute_design_matrix(X, centers, spreads):\n",
    "    # use broadcast\n",
    "    basis_func_outputs = np.exp(np.sum(np.matmul(X - centers, spreads) * (X - centers),axis=2)/(-2)).T\n",
    "    # insert ones to the 1st col\n",
    "    return np.insert(basis_func_outputs, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def design_mat_gen(total_data, m_value):\n",
    "    dic = k_means(m_value-1,total_data)\n",
    "    centers = [dic[i][\"center\"] for i in dic.keys()]\n",
    "    centers = np.array([list(i) for i in centers])\n",
    "    spreads = [dic[i][\"spread\"].tolist() for i in dic.keys()]\n",
    "    spreads = np.array(spreads)\n",
    "    design_matrix = compute_design_matrix(np.array(total_data[np.newaxis, :, :]),np.array(centers[:, np.newaxis, :]),spreads)\n",
    "    return design_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Given in ppt\n",
    "def closed_form_sol(L2_lambda, design_matrix, output_data):\n",
    "    return np.array(np.linalg.solve(\n",
    "    L2_lambda * np.identity(design_matrix.shape[1]) +\n",
    "    np.matmul(design_matrix.T, design_matrix),\n",
    "    np.matmul(design_matrix.T, output_data)\n",
    "    ).flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Given in ppt\n",
    "def SGD_sol(learning_rate,minibatch_size,num_epochs,L2_lambda,design_matrix,output_data):\n",
    "    N, _ = design_matrix.shape\n",
    "    # You can try different mini-batch size size\n",
    "    # Using minibatch_size = N is equivalent to standard gradient descent\n",
    "    # Using minibatch_size = 1 is equivalent to stochastic gradient descent\n",
    "    # In this case, minibatch_size = N is better\n",
    "    weights = np.zeros([1, len(design_matrix[0])])\n",
    "    # The more epochs the higher training accuracy. When set to 1000000,\n",
    "    # weights will be very close to closed_form_weights. But this is unnecessary\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(N / minibatch_size):\n",
    "            lower_bound = i * minibatch_size\n",
    "            upper_bound = min((i+1)*minibatch_size, N)\n",
    "            Phi = design_matrix[lower_bound : upper_bound, :]\n",
    "            t = output_data[lower_bound : upper_bound, :]\n",
    "            E_D = np.matmul((np.matmul(Phi, weights.T)-t).T,Phi)\n",
    "            E = (E_D + L2_lambda * weights) / minibatch_size\n",
    "            weights = weights - learning_rate * E\n",
    "            #print np.linalg.norm(E)\n",
    "    return weights.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(output_data,w,dm,lambda_val):\n",
    "    error = 1/2.0*sum([(output_data[i]-sum(w.T*dm[i]))**2 for i in range(len(output_data))]).tolist()[0] + lambda_val*sum(1/2.0*w.T*w)\n",
    "    return error\n",
    "\n",
    "def rms_error(error,test_data_len):\n",
    "    rms = np.sqrt(2.0*error/test_data_len)\n",
    "    return rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Synthetic or LeToR data\n",
    "input_data = letor_input_data\n",
    "output_data = letor_output_data\n",
    "\n",
    "indices = shuffle(input_data)\n",
    "mat1,mat2,mat3,tot_in = split_data(input_data,indices)\n",
    "out1,out2,out3,tot_out = split_data(output_data,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOSED FORM\n"
     ]
    }
   ],
   "source": [
    "print \"CLOSED FORM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Optimal M: 2  Current M: 2\n",
      "Latest Optimal M: 2  Current M: 3\n",
      "Latest Optimal M: 4  Current M: 4\n",
      "Latest Optimal M: 5  Current M: 5\n",
      "Latest Optimal M: 6  Current M: 6\n",
      "Latest Optimal M: 7  Current M: 7\n",
      "Latest Optimal M: 8  Current M: 8\n",
      "Latest Optimal M: 9  Current M: 9\n",
      "Latest Optimal M: 10  Current M: 10\n",
      "Latest Optimal M: 10  Current M: 11\n",
      "Latest Optimal M: 10  Current M: 12\n",
      "Latest Optimal M: 13  Current M: 13\n",
      "Latest Optimal M: 13  Current M: 14\n",
      "Latest Optimal M: 13  Current M: 15\n",
      "Latest Optimal M: 13  Current M: 16\n",
      "Latest Optimal M: 13  Current M: 17\n",
      "Latest Optimal M: 13  Current M: 18\n",
      "Latest Optimal M: 13  Current M: 19\n",
      "Latest Optimal M: 13  Current M: 20\n",
      "Latest Optimal M: 13  Current M: 21\n"
     ]
    }
   ],
   "source": [
    "#Lambda Hyperparameter\n",
    "lambda_value = 0.1\n",
    "\n",
    "#Early stop parameter\n",
    "p = 10\n",
    "j = 0\n",
    "m = 2\n",
    "\n",
    "#Initial Minimum error found during training validation cycle\n",
    "min_err_val = np.inf\n",
    "\n",
    "#Early stopping\n",
    "while (j + 2 < p):\n",
    "    #compute design matrix for hyper parameter M = m\n",
    "    design_matrix = design_mat_gen(tot_in,m)\n",
    "    \n",
    "    #split into training and validation\n",
    "    design_mat_training = design_matrix[:int(len(design_matrix)*0.8)]\n",
    "    design_mat_validation = design_matrix[int(len(design_matrix)*0.8):int(len(design_matrix)*0.9)]\n",
    "    \n",
    "    #compute min w by the closed form solution for that particular lambda and M\n",
    "    w = closed_form_sol(lambda_value,design_mat_training,out1)\n",
    "    \n",
    "    #MSE plus the regularization error\n",
    "    error_min = error(out2,w,design_mat_validation,lambda_value)\n",
    "    \n",
    "    #saving min error state\n",
    "    if (error_min < min_err_val):\n",
    "        j = 0\n",
    "        min_err_val = error_min\n",
    "        min_m = m\n",
    "        min_dm = design_matrix\n",
    "        min_w = w\n",
    "    else:\n",
    "        j +=1\n",
    "    \n",
    "    print \"Latest Optimal M:\", min_m, \" Current M:\",m\n",
    "    m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum error found in Validation set is:  1122.20322293\n",
      "Minimum RMS error found in Validation set is:  0.567784776736\n",
      "RMS in test data is:  0.578164370826\n"
     ]
    }
   ],
   "source": [
    "mat2_dm = min_dm[int(len(design_matrix)*0.8):int(len(design_matrix)*0.9)]\n",
    "mat3_dm = min_dm[int(len(design_matrix)*0.9):]\n",
    "\n",
    "print \"Minimum error found in Validation set is: \", min_err_val\n",
    "print \"Minimum RMS error found in Validation set is: \", rms_error(min_err_val,len(mat2_dm))\n",
    "\n",
    "error_test = rms_error(error(out3,min_w,mat3_dm,lambda_value),len(mat3_dm))\n",
    "\n",
    "print \"RMS in test data is: \", error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOCHASTIC GRADIENT DESCENT\n"
     ]
    }
   ],
   "source": [
    "print \"STOCHASTIC GRADIENT DESCENT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Optimal M: 2  Current M: 2\n",
      "Latest Optimal M: 3  Current M: 3\n",
      "Latest Optimal M: 4  Current M: 4\n",
      "Latest Optimal M: 5  Current M: 5\n",
      "Latest Optimal M: 6  Current M: 6\n",
      "Latest Optimal M: 6  Current M: 7\n",
      "Latest Optimal M: 8  Current M: 8\n",
      "Latest Optimal M: 9  Current M: 9\n",
      "Latest Optimal M: 10  Current M: 10\n",
      "Latest Optimal M: 11  Current M: 11\n",
      "Latest Optimal M: 12  Current M: 12\n",
      "Latest Optimal M: 13  Current M: 13\n",
      "Latest Optimal M: 14  Current M: 14\n"
     ]
    }
   ],
   "source": [
    "#Early stop parameter\n",
    "p = 10\n",
    "j = 0\n",
    "\n",
    "#Hyperparameters\n",
    "lambda_value = 0.1\n",
    "learn_rate = 0.01\n",
    "m = 2\n",
    "\n",
    "#Initial Minimum error found during training validation cycle\n",
    "min_err_val = np.inf\n",
    "\n",
    "#Early stopping\n",
    "while (j + 2 < p):\n",
    "    #compute design matrix for hyper parameter M = m\n",
    "    design_matrix = design_mat_gen(tot_in,m)\n",
    "    N, D = mat1.shape\n",
    "    #split into training and validation\n",
    "    design_mat_training = design_matrix[:int(len(design_matrix)*0.8)]\n",
    "    design_mat_validation = design_matrix[int(len(design_matrix)*0.8):int(len(design_matrix)*0.9)]\n",
    "    \n",
    "    #Gradient Descent solution for min w\n",
    "    w_sgd = SGD_sol(learning_rate=learn_rate,minibatch_size=N,num_epochs=10000,L2_lambda=lambda_value,design_matrix=design_mat_training,output_data=out1)\n",
    "    w_sgd = np.array(w_sgd.tolist())\n",
    "    \n",
    "    #MSE plus the regularization error\n",
    "    error_min = error(out2,w_sgd,design_mat_validation,lambda_value)\n",
    "    \n",
    "    #saving min error state\n",
    "    if (error_min < min_err_val):\n",
    "        j = 0\n",
    "        min_err_val = error_min\n",
    "        min_m = m\n",
    "        min_dm = design_matrix\n",
    "        min_w = w_sgd\n",
    "    else:\n",
    "        j += 1\n",
    "        \n",
    "    print \"Latest Optimal M:\", min_m, \" Current M:\",m\n",
    "    m += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2_dm = min_dm[int(len(design_matrix)*0.8):int(len(design_matrix)*0.9)]\n",
    "mat3_dm = min_dm[int(len(design_matrix)*0.9):]\n",
    "\n",
    "print \"Minimum error found in Validation set is: \", min_err_val\n",
    "print \"Minimum RMS error found in Validation set is: \", rms_error(min_err_val,len(mat2_dm))\n",
    "\n",
    "error_test = rms_error(error(out3,min_w,mat3_dm,lambda_value),len(mat3_dm))\n",
    "\n",
    "print \"RMS in test data is: \", error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "input_data = letor_input_data\n",
    "output_data = letor_output_data\n",
    "N, D = input_data.shape\n",
    "# Assume we use 3 Gaussian basis functions M = 3\n",
    "# shape = [M, 1, D]\n",
    "centers = np.array([np.ones((D))*1, np.ones((D))*0.5, np.ones((D))*1.5])\n",
    "centers = centers[:, np.newaxis, :]\n",
    "# shape = [M, D, D]\n",
    "spreads = np.array([np.identity(D), np.identity(D), np.identity(D)]) * 0.5\n",
    "# shape = [1, N, D]\n",
    "X = input_data[np.newaxis, :, :]\n",
    "design_matrix = compute_design_matrix(X, centers, spreads)\n",
    "\n",
    "\n",
    "# Closed-form solution\n",
    "print closed_form_sol(L2_lambda=0.1,design_matrix=design_matrix,output_data=output_data)\n",
    "# Gradient descent solution\n",
    "print SGD_sol(learning_rate=1,minibatch_size=N,num_epochs=10000,L2_lambda=0.1,design_matrix=design_matrix,output_data=output_data)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
